###             3 = alpha parameter for second dist
###             4 = beta parameter for second dist
###             5 = the class split
### n_iter: the number of times the estimation process will be run to generate results
alpha1 <- init_params[1]
beta1 <- init_params[2]
alpha2 <- init_params[3]
beta2 <- init_params[4]
pi <- init_params[5]
resp <- NULL
initial_pop1 <- NULL
initial_pop2 <- NULL
for (i in 1:length(x)){
initial_pop1[i] <- pbeta(x[i], alpha1, beta1, ncp = 0, lower.tail = TRUE, log.p = FALSE)
initial_pop2[i] <- pbeta(x[i], alpha2, beta2, ncp = 0, lower.tail = TRUE, log.p = FALSE)
resp[i] = (pi * initial_pop2[i]) / ((1 - pi) * initial_pop1[i] + pi * initial_pop2[i])
#### Now want to add bernoulli random draws to split into two classes. Split determined on pi
#### Iterate over these draws 8000-10000 times to get median parameters for next iteration
#### Keep going until we get convergence
}
nrow <- NULL
shape1 <- NULL
shape2 <- NULL
for (i in 1:n_iter){
class_member <- rbinom(n = 8000, size = 1, prob = pi)
#### Do I fit the beta distributions based on the observations or the responsiveness measure for the classes?
results <- data.frame(obs = x, resp = resp, class = class_member)
pop1 <- as.matrix(results$population[results$class == 1])
pop2 <- as.matrix(results$population[results$class == 0])
parameters <- list(alpha1, beta1)
dist_1 <- fit_beta(pop1, parameters)
#nrow[i] <- i
#shape1[i] <- dist_1[1]
#shape2[i] <- dist_1[2]
}
#shape_total_draws <- list(nrow, shape1, shape2)
#return(shape_total_draws)
return(parameters)
}
init_dists <- comp_resp(pop, init, 8)
library(MASS)
library(ggplot2)
library(dplyr)
#### Reading in the data
op <- options(digits = 7)
rm(list = ls())
basepath <- 'C:/Users/evanm_000/Documents/GitHub/mixture-models'
setwd(basepath)
data <- read.table("EvanExercise.dat", header=FALSE)
colnames(data) <- 'population'
#### Getting an overview of what the data looks like
ggplot(data, aes(x = population)) + geom_density() + xlim(0, 1.1) +theme_minimal() + ggtitle('Overview of population')
set.seed(737)
pop = as.matrix(data)
#### Starting points are as below. Will use K means to generate more reasonable estimates in future
#### Reducing the size of the starting points to make them more feasible
alpha1 <- 0.5
beta1 <- 0.125
alpha2 <- 0.5
beta2 <- 0.25
pi <- 0.5
init <- c(alpha1, beta1, alpha2, beta2, pi)
initial <- pop[1]
fit_beta <- function(pop, params){
### df: the dataframe of results containing:
###     obs: the original observations
###     resp: the class responsiveness
### params: the parameters required for fitting the beta distribution
beta_dist <- fitdistr(pop, dbeta, list(shape1 = params[1], shape2 = params[2]))
dist <- c(beta_dist$estimate['shape1'], beta_dist1$estimate['shape2'])
return(dist)
}
comp_resp <- function(x, init_params, n_iter){
### x: the observations for which responsibilties will be calculated
### init_params: the initial values for the beta distributions
###             1 = alpha parameter for first dist
###             2 = beta parameter for first dist
###             3 = alpha parameter for second dist
###             4 = beta parameter for second dist
###             5 = the class split
### n_iter: the number of times the estimation process will be run to generate results
alpha1 <- init_params[1]
beta1 <- init_params[2]
alpha2 <- init_params[3]
beta2 <- init_params[4]
pi <- init_params[5]
resp <- NULL
initial_pop1 <- NULL
initial_pop2 <- NULL
for (i in 1:length(x)){
initial_pop1[i] <- pbeta(x[i], alpha1, beta1, ncp = 0, lower.tail = TRUE, log.p = FALSE)
initial_pop2[i] <- pbeta(x[i], alpha2, beta2, ncp = 0, lower.tail = TRUE, log.p = FALSE)
resp[i] = (pi * initial_pop2[i]) / ((1 - pi) * initial_pop1[i] + pi * initial_pop2[i])
#### Now want to add bernoulli random draws to split into two classes. Split determined on pi
#### Iterate over these draws 8000-10000 times to get median parameters for next iteration
#### Keep going until we get convergence
}
nrow <- NULL
shape1 <- NULL
shape2 <- NULL
for (i in 1:n_iter){
class_member <- rbinom(n = 8000, size = 1, prob = pi)
#### Do I fit the beta distributions based on the observations or the responsiveness measure for the classes?
results <- data.frame(obs = x, resp = resp, class = class_member)
pop1 <- as.matrix(results$population[results$class == 1])
pop2 <- as.matrix(results$population[results$class == 0])
parameters <- list(alpha1, beta1)
dist_1 <- fit_beta(pop1, parameters)
#nrow[i] <- i
#shape1[i] <- dist_1[1]
#shape2[i] <- dist_1[2]
}
#shape_total_draws <- list(nrow, shape1, shape2)
#return(shape_total_draws)
return(pop1)
}
init_dists <- comp_resp(pop, init, 1)
library(MASS)
library(ggplot2)
library(dplyr)
#### Reading in the data
op <- options(digits = 7)
rm(list = ls())
basepath <- 'C:/Users/evanm_000/Documents/GitHub/mixture-models'
setwd(basepath)
data <- read.table("EvanExercise.dat", header=FALSE)
colnames(data) <- 'population'
#### Getting an overview of what the data looks like
ggplot(data, aes(x = population)) + geom_density() + xlim(0, 1.1) +theme_minimal() + ggtitle('Overview of population')
set.seed(737)
pop = as.matrix(data)
#### Starting points are as below. Will use K means to generate more reasonable estimates in future
#### Reducing the size of the starting points to make them more feasible
alpha1 <- 0.5
beta1 <- 0.125
alpha2 <- 0.5
beta2 <- 0.25
pi <- 0.5
init <- c(alpha1, beta1, alpha2, beta2, pi)
initial <- pop[1]
fit_beta <- function(pop, params){
### df: the dataframe of results containing:
###     obs: the original observations
###     resp: the class responsiveness
### params: the parameters required for fitting the beta distribution
beta_dist <- fitdistr(pop, dbeta, list(shape1 = params[1], shape2 = params[2]))
dist <- c(beta_dist$estimate['shape1'], beta_dist1$estimate['shape2'])
return(dist)
}
comp_resp <- function(x, init_params, n_iter){
### x: the observations for which responsibilties will be calculated
### init_params: the initial values for the beta distributions
###             1 = alpha parameter for first dist
###             2 = beta parameter for first dist
###             3 = alpha parameter for second dist
###             4 = beta parameter for second dist
###             5 = the class split
### n_iter: the number of times the estimation process will be run to generate results
alpha1 <- init_params[1]
beta1 <- init_params[2]
alpha2 <- init_params[3]
beta2 <- init_params[4]
pi <- init_params[5]
resp <- NULL
initial_pop1 <- NULL
initial_pop2 <- NULL
for (i in 1:length(x)){
initial_pop1[i] <- pbeta(x[i], alpha1, beta1, ncp = 0, lower.tail = TRUE, log.p = FALSE)
initial_pop2[i] <- pbeta(x[i], alpha2, beta2, ncp = 0, lower.tail = TRUE, log.p = FALSE)
resp[i] = (pi * initial_pop2[i]) / ((1 - pi) * initial_pop1[i] + pi * initial_pop2[i])
#### Now want to add bernoulli random draws to split into two classes. Split determined on pi
#### Iterate over these draws 8000-10000 times to get median parameters for next iteration
#### Keep going until we get convergence
}
nrow <- NULL
shape1 <- NULL
shape2 <- NULL
for (i in 1:n_iter){
class_member <- rbinom(n = 8000, size = 1, prob = pi)
#### Do I fit the beta distributions based on the observations or the responsiveness measure for the classes?
results <- data.frame(obs = x, resp = resp, class = class_member)
pop1 <- as.matrix(results$population[results$class == 1])
pop2 <- as.matrix(results$population[results$class == 0])
parameters <- list(alpha1, beta1)
#dist_1 <- fit_beta(pop1, parameters)
#nrow[i] <- i
#shape1[i] <- dist_1[1]
#shape2[i] <- dist_1[2]
}
#shape_total_draws <- list(nrow, shape1, shape2)
#return(shape_total_draws)
return(pop1)
}
init_dists <- comp_resp(pop, init, 1)
init_dists
library(MASS)
library(ggplot2)
library(dplyr)
#### Reading in the data
op <- options(digits = 7)
rm(list = ls())
basepath <- 'C:/Users/evanm_000/Documents/GitHub/mixture-models'
setwd(basepath)
data <- read.table("EvanExercise.dat", header=FALSE)
colnames(data) <- 'population'
#### Getting an overview of what the data looks like
ggplot(data, aes(x = population)) + geom_density() + xlim(0, 1.1) +theme_minimal() + ggtitle('Overview of population')
set.seed(737)
pop = as.matrix(data)
#### Starting points are as below. Will use K means to generate more reasonable estimates in future
#### Reducing the size of the starting points to make them more feasible
alpha1 <- 0.5
beta1 <- 0.125
alpha2 <- 0.5
beta2 <- 0.25
pi <- 0.5
init <- c(alpha1, beta1, alpha2, beta2, pi)
initial <- pop[1]
fit_beta <- function(pop, params){
### df: the dataframe of results containing:
###     obs: the original observations
###     resp: the class responsiveness
### params: the parameters required for fitting the beta distribution
beta_dist <- fitdistr(pop, dbeta, list(shape1 = params[1], shape2 = params[2]))
dist <- c(beta_dist$estimate['shape1'], beta_dist1$estimate['shape2'])
return(dist)
}
comp_resp <- function(x, init_params, n_iter){
### x: the observations for which responsibilties will be calculated
### init_params: the initial values for the beta distributions
###             1 = alpha parameter for first dist
###             2 = beta parameter for first dist
###             3 = alpha parameter for second dist
###             4 = beta parameter for second dist
###             5 = the class split
### n_iter: the number of times the estimation process will be run to generate results
alpha1 <- init_params[1]
beta1 <- init_params[2]
alpha2 <- init_params[3]
beta2 <- init_params[4]
pi <- init_params[5]
resp <- NULL
initial_pop1 <- NULL
initial_pop2 <- NULL
for (i in 1:length(x)){
initial_pop1[i] <- pbeta(x[i], alpha1, beta1, ncp = 0, lower.tail = TRUE, log.p = FALSE)
initial_pop2[i] <- pbeta(x[i], alpha2, beta2, ncp = 0, lower.tail = TRUE, log.p = FALSE)
resp[i] = (pi * initial_pop2[i]) / ((1 - pi) * initial_pop1[i] + pi * initial_pop2[i])
#### Now want to add bernoulli random draws to split into two classes. Split determined on pi
#### Iterate over these draws 8000-10000 times to get median parameters for next iteration
#### Keep going until we get convergence
}
nrow <- NULL
shape1 <- NULL
shape2 <- NULL
for (i in 1:n_iter){
class_member <- rbinom(n = 8000, size = 1, prob = pi)
#### Do I fit the beta distributions based on the observations or the responsiveness measure for the classes?
results <- data.frame(obs = x, resp = resp, class = class_member)
pop1 <- as.matrix(results$population[results$class == 1])
pop2 <- as.matrix(results$population[results$class == 0])
parameters <- list(alpha1, beta1)
#dist_1 <- fit_beta(pop1, parameters)
#nrow[i] <- i
#shape1[i] <- dist_1[1]
#shape2[i] <- dist_1[2]
}
#shape_total_draws <- list(nrow, shape1, shape2)
#return(shape_total_draws)
return(results)
}
init_dists <- comp_resp(pop, init, 1)
init_dists
View(init_dists)
library(MASS)
library(ggplot2)
library(dplyr)
#### Reading in the data
op <- options(digits = 7)
rm(list = ls())
basepath <- 'C:/Users/evanm_000/Documents/GitHub/mixture-models'
setwd(basepath)
data <- read.table("EvanExercise.dat", header=FALSE)
colnames(data) <- 'population'
#### Getting an overview of what the data looks like
ggplot(data, aes(x = population)) + geom_density() + xlim(0, 1.1) +theme_minimal() + ggtitle('Overview of population')
set.seed(737)
pop = as.matrix(data)
#### Starting points are as below. Will use K means to generate more reasonable estimates in future
#### Reducing the size of the starting points to make them more feasible
alpha1 <- 0.5
beta1 <- 0.125
alpha2 <- 0.5
beta2 <- 0.25
pi <- 0.5
init <- c(alpha1, beta1, alpha2, beta2, pi)
initial <- pop[1]
fit_beta <- function(pop, params){
### df: the dataframe of results containing:
###     obs: the original observations
###     resp: the class responsiveness
### params: the parameters required for fitting the beta distribution
beta_dist <- fitdistr(pop, dbeta, list(shape1 = params[1], shape2 = params[2]))
dist <- c(beta_dist$estimate['shape1'], beta_dist1$estimate['shape2'])
return(dist)
}
comp_resp <- function(x, init_params, n_iter){
### x: the observations for which responsibilties will be calculated
### init_params: the initial values for the beta distributions
###             1 = alpha parameter for first dist
###             2 = beta parameter for first dist
###             3 = alpha parameter for second dist
###             4 = beta parameter for second dist
###             5 = the class split
### n_iter: the number of times the estimation process will be run to generate results
x <- as.matrix(x)
alpha1 <- init_params[1]
beta1 <- init_params[2]
alpha2 <- init_params[3]
beta2 <- init_params[4]
pi <- init_params[5]
resp <- NULL
initial_pop1 <- NULL
initial_pop2 <- NULL
for (i in 1:length(x)){
initial_pop1[i] <- pbeta(x[i], alpha1, beta1, ncp = 0, lower.tail = TRUE, log.p = FALSE)
initial_pop2[i] <- pbeta(x[i], alpha2, beta2, ncp = 0, lower.tail = TRUE, log.p = FALSE)
resp[i] = (pi * initial_pop2[i]) / ((1 - pi) * initial_pop1[i] + pi * initial_pop2[i])
#### Now want to add bernoulli random draws to split into two classes. Split determined on pi
#### Iterate over these draws 8000-10000 times to get median parameters for next iteration
#### Keep going until we get convergence
}
nrow <- NULL
shape1 <- NULL
shape2 <- NULL
for (i in 1:n_iter){
class_member <- rbinom(n = 8000, size = 1, prob = pi)
#### Do I fit the beta distributions based on the observations or the responsiveness measure for the classes?
results <- data.frame(obs = x, resp = resp, class = class_member)
pop1 <- as.matrix(results$population[results$class == 1])
pop2 <- as.matrix(results$population[results$class == 0])
parameters <- list(alpha1, beta1)
#dist_1 <- fit_beta(pop1, parameters)
#nrow[i] <- i
#shape1[i] <- dist_1[1]
#shape2[i] <- dist_1[2]
}
#shape_total_draws <- list(nrow, shape1, shape2)
#return(shape_total_draws)
return(results)
}
init_dists <- comp_resp(pop, init, 1)
View(init_dists)
View(data)
library(MASS)
library(ggplot2)
library(dplyr)
#### Reading in the data
op <- options(digits = 7)
rm(list = ls())
basepath <- 'C:/Users/evanm_000/Documents/GitHub/mixture-models'
setwd(basepath)
data <- read.table("EvanExercise.dat", header=FALSE)
colnames(data) <- 'population'
#### Getting an overview of what the data looks like
ggplot(data, aes(x = population)) + geom_density() + xlim(0, 1.1) +theme_minimal() + ggtitle('Overview of population')
set.seed(737)
pop = as.matrix(data)
#### Starting points are as below. Will use K means to generate more reasonable estimates in future
#### Reducing the size of the starting points to make them more feasible
alpha1 <- 0.5
beta1 <- 0.125
alpha2 <- 0.5
beta2 <- 0.25
pi <- 0.5
init <- c(alpha1, beta1, alpha2, beta2, pi)
initial <- pop[1]
fit_beta <- function(pop, params){
### df: the dataframe of results containing:
###     obs: the original observations
###     resp: the class responsiveness
### params: the parameters required for fitting the beta distribution
beta_dist <- fitdistr(pop, dbeta, list(shape1 = params[1], shape2 = params[2]))
dist <- c(beta_dist$estimate['shape1'], beta_dist1$estimate['shape2'])
return(dist)
}
comp_resp <- function(x, init_params, n_iter){
### x: the observations for which responsibilties will be calculated
### init_params: the initial values for the beta distributions
###             1 = alpha parameter for first dist
###             2 = beta parameter for first dist
###             3 = alpha parameter for second dist
###             4 = beta parameter for second dist
###             5 = the class split
### n_iter: the number of times the estimation process will be run to generate results
x <- as.matrix(x)
alpha1 <- init_params[1]
beta1 <- init_params[2]
alpha2 <- init_params[3]
beta2 <- init_params[4]
pi <- init_params[5]
resp <- NULL
initial_pop1 <- NULL
initial_pop2 <- NULL
for (i in 1:length(x)){
initial_pop1[i] <- pbeta(x[i], alpha1, beta1, ncp = 0, lower.tail = TRUE, log.p = FALSE)
initial_pop2[i] <- pbeta(x[i], alpha2, beta2, ncp = 0, lower.tail = TRUE, log.p = FALSE)
resp[i] = (pi * initial_pop2[i]) / ((1 - pi) * initial_pop1[i] + pi * initial_pop2[i])
#### Now want to add bernoulli random draws to split into two classes. Split determined on pi
#### Iterate over these draws 8000-10000 times to get median parameters for next iteration
#### Keep going until we get convergence
}
nrow <- NULL
shape1 <- NULL
shape2 <- NULL
for (i in 1:n_iter){
class_member <- rbinom(n = 8000, size = 1, prob = pi)
#### Do I fit the beta distributions based on the observations or the responsiveness measure for the classes?
results <- data.frame(obs = x, resp = resp, class = class_member)
pop1 <- as.matrix(results$obs[results$class == 1])
pop2 <- as.matrix(results$obs[results$class == 0])
parameters <- list(alpha1, beta1)
dist_1 <- fit_beta(pop1, parameters)
#nrow[i] <- i
#shape1[i] <- dist_1[1]
#shape2[i] <- dist_1[2]
}
#shape_total_draws <- list(nrow, shape1, shape2)
#return(shape_total_draws)
return(results)
}
init_dists <- comp_resp(pop, init, 1)
View(pop)
library(MASS)
library(ggplot2)
library(dplyr)
#### Reading in the data
op <- options(digits = 7)
rm(list = ls())
basepath <- 'C:/Users/evanm_000/Documents/GitHub/mixture-models'
setwd(basepath)
data <- read.table("EvanExercise.dat", header=FALSE)
colnames(data) <- 'population'
#### Getting an overview of what the data looks like
ggplot(data, aes(x = population)) + geom_density() + xlim(0, 1.1) +theme_minimal() + ggtitle('Overview of population')
set.seed(737)
pop = as.matrix(data)
#### Starting points are as below. Will use K means to generate more reasonable estimates in future
#### Reducing the size of the starting points to make them more feasible
alpha1 <- 0.5
beta1 <- 0.125
alpha2 <- 0.5
beta2 <- 0.25
pi <- 0.5
init <- c(alpha1, beta1, alpha2, beta2, pi)
initial <- pop[1]
fit_beta <- function(pop, params){
### df: the dataframe of results containing:
###     obs: the original observations
###     resp: the class responsiveness
### params: the parameters required for fitting the beta distribution
beta_dist <- fitdistr(pop, dbeta, list(shape1 = params[1], shape2 = params[2]))
dist <- c(beta_dist$estimate['shape1'], beta_dist1$estimate['shape2'])
return(dist)
}
comp_resp <- function(x, init_params, n_iter){
### x: the observations for which responsibilties will be calculated
### init_params: the initial values for the beta distributions
###             1 = alpha parameter for first dist
###             2 = beta parameter for first dist
###             3 = alpha parameter for second dist
###             4 = beta parameter for second dist
###             5 = the class split
### n_iter: the number of times the estimation process will be run to generate results
x <- as.matrix(x)
alpha1 <- init_params[1]
beta1 <- init_params[2]
alpha2 <- init_params[3]
beta2 <- init_params[4]
pi <- init_params[5]
resp <- NULL
initial_pop1 <- NULL
initial_pop2 <- NULL
for (i in 1:length(x)){
initial_pop1[i] <- pbeta(x[i], alpha1, beta1, ncp = 0, lower.tail = TRUE, log.p = FALSE)
initial_pop2[i] <- pbeta(x[i], alpha2, beta2, ncp = 0, lower.tail = TRUE, log.p = FALSE)
resp[i] = (pi * initial_pop2[i]) / ((1 - pi) * initial_pop1[i] + pi * initial_pop2[i])
#### Now want to add bernoulli random draws to split into two classes. Split determined on pi
#### Iterate over these draws 8000-10000 times to get median parameters for next iteration
#### Keep going until we get convergence
}
nrow <- NULL
shape1 <- NULL
shape2 <- NULL
for (i in 1:n_iter){
class_member <- rbinom(n = 8000, size = 1, prob = pi)
#### Do I fit the beta distributions based on the observations or the responsiveness measure for the classes?
results <- data.frame(obs = x, resp = resp, class = class_member)
#pop1 <- as.matrix(results$obs[results$class == 1])
#pop2 <- as.matrix(results$obs[results$class == 0])
#parameters <- list(alpha1, beta1)
#dist_1 <- fit_beta(pop1, parameters)
#nrow[i] <- i
#shape1[i] <- dist_1[1]
#shape2[i] <- dist_1[2]
}
#shape_total_draws <- list(nrow, shape1, shape2)
#return(shape_total_draws)
return(results)
}
init_dists <- comp_resp(pop, init, 1)
View(init_dists)
